# gpu-100-days

### Learn You a GPU for Great Good (in public)!

- [Day 1: Your GPU is a Monster. Don't Let It Starve](./day-1.md) -> Max out every part of the GPU (a napkin math first)

- [Day 2: A High-Level Overview of LLM Systems](./day-2.md) -> A broad overview without getting lost in technical details

- [Day 3: Writing Your First CUDA Kernel](./day-3.md) -> Introduction to GPU programming with a simple CUDA kernel

- [Day 4: The Art of Pointer Arithmetic](./day-4.md) -> The underlying memory layout of tensor representiaobn

- [Day 5: Tiling and Shared Memory](./day-5.md) ->  Dividing the matrix into blocks that fit within the cache

- [Day 6: Global Memory Coalescing](./day-6.md) -> Combining adjacent accesses into single memory transaction

- [Day 7: RL in LLM Post-training](./day-7.md) -> This is the way LLMs can do reasoning

- [Day 8: RL Framework Design Space](./day-8.md) -> Discuss RL infra form factor

- [Day 9: Setting Up RL Infra](./day-9.md) -> The logs of me playing [Slime](https://github.com/THUDM/slime)

- [Day 10: Notes from VeRL Talk](./day-10.md) -> 
A write-up of Haibin Linâ€™s introduction and Q&A on [VeRL](https://github.com/volcengine/verl) at PyTorch Webinar